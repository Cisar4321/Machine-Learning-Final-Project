{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab2498dc",
   "metadata": {},
   "source": [
    "# ü•î 02_features_clustering.ipynb\n",
    "## Extracci√≥n de caracter√≠sticas y clustering para limpieza de dataset de hojas de papa\n",
    "Este notebook realiza:\n",
    "1. Extracci√≥n de embeddings con MobileNetV2.\n",
    "2. Clustering dentro de cada clase para detectar y eliminar im√°genes at√≠picas (ruido).\n",
    "3. Guarda los embeddings limpios para entrenamiento posterior de un clasificador.\n",
    "\n",
    "Se asume que las im√°genes ya fueron preprocesadas (resize, contraste condicional, normalizaci√≥n).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb754942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# --------------------------\n",
    "data_dir = Path(\"../data/2_data_resize\")  # Dataset preprocesado\n",
    "output_dir = Path(\"../data/4_features_embeddings\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07754606",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Cargar MobileNetV2 preentrenado\n",
    "Se usa MobileNetV2 sin la capa de clasificaci√≥n (`include_top=False`) para extraer embeddings de cada imagen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bc64d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo MobileNetV2 para extracci√≥n de features\n",
    "model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef040a",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Funci√≥n para leer y preprocesar im√°genes\n",
    "Convierte las im√°genes a RGB, aplica `preprocess_input` de MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7a2b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(img_path):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img = preprocess_input(img.astype('float32'))  # Escala -1 a 1\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d693b96",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Extraer embeddings por clase\n",
    "Se recorren todas las clases, se extraen embeddings y se almacenan para clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b636ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Bacteria: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 569/569 [04:10<00:00,  2.27it/s]\n",
      "Procesando Fungi: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 748/748 [05:45<00:00,  2.16it/s]\n",
      "Procesando Healthy: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [01:22<00:00,  2.43it/s]\n",
      "Procesando Nematode: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 68/68 [00:27<00:00,  2.44it/s]\n",
      "Procesando Pest: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 611/611 [04:19<00:00,  2.35it/s]\n",
      "Procesando Phytopthora: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 347/347 [03:00<00:00,  1.92it/s]\n",
      "Procesando Virus: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 532/532 [03:40<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = {}\n",
    "labels_dict = {}\n",
    "\n",
    "for class_folder in sorted(os.listdir(data_dir)):\n",
    "    class_path = data_dir / class_folder\n",
    "    if not class_path.is_dir():\n",
    "        continue\n",
    "\n",
    "    embeddings = []\n",
    "    image_files = []\n",
    "\n",
    "    for img_file in tqdm(os.listdir(class_path), desc=f\"Procesando {class_folder}\"):\n",
    "        img_path = class_path / img_file\n",
    "        img = load_and_preprocess(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # Extraer embedding\n",
    "        emb = model.predict(np.expand_dims(img, axis=0), verbose=0)\n",
    "        embeddings.append(emb.flatten())\n",
    "        image_files.append(img_file)\n",
    "\n",
    "    embeddings = np.array(embeddings)\n",
    "    embeddings_dict[class_folder] = embeddings\n",
    "    labels_dict[class_folder] = image_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1375af51",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Clustering para eliminar outliers\n",
    "Se aplica DBSCAN a los embeddings de cada clase. Los puntos etiquetados como `-1` se consideran outliers y se eliminan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e080aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bacteria: 569 im√°genes ‚Üí 569 limpias, 0 sospechosas (eps final=15.73)\n",
      "Fungi: 748 im√°genes ‚Üí 748 limpias, 0 sospechosas (eps final=15.73)\n",
      "Healthy: 201 im√°genes ‚Üí 198 limpias, 3 sospechosas (eps final=15.73)\n",
      "Nematode: 68 im√°genes ‚Üí 67 limpias, 1 sospechosas (eps final=25.17)\n",
      "Pest: 611 im√°genes ‚Üí 610 limpias, 1 sospechosas (eps final=15.73)\n",
      "Phytopthora: 347 im√°genes ‚Üí 340 limpias, 7 sospechosas (eps final=15.73)\n",
      "Virus: 532 im√°genes ‚Üí 531 limpias, 1 sospechosas (eps final=15.73)\n",
      "Proceso completado. Embeddings/labels limpias y sospechosas guardadas. Revisa la carpeta 'suspect_images' para inspecci√≥n manual.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# BLOQUE: Clustering adaptativo por clase (garantiza retenci√≥n m√≠nima)\n",
    "# ------------------------------\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "import shutil\n",
    "\n",
    "# Par√°metros ajustables\n",
    "PCA_DIM = 30\n",
    "INITIAL_EPS = 1.5\n",
    "EPS_MULT = 1.6       # factor para ir aumentando eps si se elimina demasiado\n",
    "MAX_EPS = 80.0\n",
    "MIN_SAMPLES = 3\n",
    "MIN_KEEP_RATIO = 0.90   # queremos conservar al menos 90% por clase\n",
    "\n",
    "# Carpetas para sospechosas\n",
    "suspect_dir = output_dir / \"suspect_images\"\n",
    "suspect_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "clean_embeddings = {}\n",
    "clean_labels = {}\n",
    "suspect_labels = {}\n",
    "\n",
    "for class_name, embeddings in embeddings_dict.items():\n",
    "    n_total = len(embeddings)\n",
    "    if n_total == 0:\n",
    "        clean_embeddings[class_name] = embeddings\n",
    "        clean_labels[class_name] = []\n",
    "        suspect_labels[class_name] = []\n",
    "        print(f\"{class_name}: 0 im√°genes (skip).\")\n",
    "        continue\n",
    "\n",
    "    if n_total < 5:\n",
    "        # Si muy pocas im√°genes, no clusterizamos autom√°ticamente\n",
    "        clean_embeddings[class_name] = embeddings\n",
    "        clean_labels[class_name] = labels_dict[class_name]\n",
    "        suspect_labels[class_name] = []\n",
    "        print(f\"{class_name}: {n_total} im√°genes (<5) ‚Üí no se clusteriza, se conservan todas.\")\n",
    "        continue\n",
    "\n",
    "    # PCA reducci√≥n\n",
    "    pca = PCA(n_components=min(PCA_DIM, n_total))  # no pedir m√°s comps que muestras\n",
    "    embeddings_reduced = pca.fit_transform(embeddings)\n",
    "\n",
    "    # intento adaptativo con DBSCAN aumentando eps hasta cumplir MIN_KEEP_RATIO\n",
    "    eps = INITIAL_EPS\n",
    "    final_mask = None\n",
    "    final_labels = None\n",
    "\n",
    "    while True:\n",
    "        clusterer = DBSCAN(eps=eps, min_samples=MIN_SAMPLES, metric='euclidean')\n",
    "        cluster_labels = clusterer.fit_predict(embeddings_reduced)  # -1 = outlier\n",
    "        mask = cluster_labels != -1\n",
    "        kept = mask.sum()\n",
    "        keep_ratio = kept / n_total\n",
    "\n",
    "        # Si cumplimos la proporci√≥n m√≠nima, aceptamos\n",
    "        if keep_ratio >= MIN_KEEP_RATIO:\n",
    "            final_mask = mask\n",
    "            final_labels = cluster_labels\n",
    "            break\n",
    "\n",
    "        # Si eps ya demasiado grande, no eliminar nada (fallback seguro)\n",
    "        if eps >= MAX_EPS:\n",
    "            final_mask = np.ones(n_total, dtype=bool)  # conservar todo\n",
    "            final_labels = np.zeros(n_total, dtype=int)  # todos en un cluster ficticio\n",
    "            print(f\"{class_name}: No se pudo alcanzar keep_ratio={MIN_KEEP_RATIO:.2f} incluso con eps={eps:.1f}. Conservando todo (fallback).\")\n",
    "            break\n",
    "\n",
    "        # aumentar eps y reintentar\n",
    "        eps *= EPS_MULT\n",
    "\n",
    "    # Aplicar m√°scara final\n",
    "    mask = final_mask\n",
    "    kept_idx = np.where(mask)[0]\n",
    "    suspect_idx = np.where(~mask)[0]\n",
    "\n",
    "    clean_embeddings[class_name] = embeddings[kept_idx]\n",
    "    clean_labels[class_name] = np.array(labels_dict[class_name])[kept_idx].tolist()\n",
    "    suspect_labels[class_name] = np.array(labels_dict[class_name])[suspect_idx].tolist()\n",
    "\n",
    "    # Reporte por clase\n",
    "    print(f\"{class_name}: {n_total} im√°genes ‚Üí {len(clean_labels[class_name])} limpias, {len(suspect_labels[class_name])} sospechosas (eps final={eps:.2f})\")\n",
    "\n",
    "    # Mover/copiar im√°genes sospechosas a carpeta de revisi√≥n (no borra nada)\n",
    "    class_suspect_dir = suspect_dir / class_name\n",
    "    class_suspect_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for fname in suspect_labels[class_name]:\n",
    "        src = data_dir / class_name / fname\n",
    "        dst = class_suspect_dir / fname\n",
    "        if src.exists():\n",
    "            # copia por seguridad (si dataset grande, podr√≠as cambiar a move)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "# Guardar resultados\n",
    "with open(output_dir / \"embeddings_clean.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clean_embeddings, f)\n",
    "\n",
    "with open(output_dir / \"labels_clean.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clean_labels, f)\n",
    "\n",
    "with open(output_dir / \"labels_suspect.pkl\", \"wb\") as f:\n",
    "    pickle.dump(suspect_labels, f)\n",
    "\n",
    "print(\"Proceso completado. Embeddings/labels limpias y sospechosas guardadas. Revisa la carpeta 'suspect_images' para inspecci√≥n manual.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15adef97",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Guardar embeddings y etiquetas limpias\n",
    "Se guardan en formato pickle para entrenamiento posterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7695a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings y etiquetas limpias guardadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "with open(output_dir / \"embeddings_clean.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clean_embeddings, f)\n",
    "\n",
    "with open(output_dir / \"labels_clean.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clean_labels, f)\n",
    "\n",
    "print(\"Embeddings y etiquetas limpias guardadas correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9144b4fc",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Visualizaci√≥n de clusters y outliers\n",
    "Aqu√≠ proyectaremos los embeddings de cada clase en 2D para ver c√≥mo se agrupan y cu√°les se consideran outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b365a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ']' (301075031.py, line 79)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mclean_labels[class_name] = np.array(labels_dict[class_name])[kept_idx].tolis_]()_]()]()_\u001b[39m\n                                                                                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ']'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for class_name, embeddings in clean_embeddings.items():\n",
    "    if len(embeddings) < 5:\n",
    "        continue\n",
    "\n",
    "    # PCA a 2D\n",
    "    pca = PCA(n_components=2)\n",
    "    emb_2d = pca.fit_transform(embeddings_dict[class_name])  # usamos todos los embeddings originales para ver outliers\n",
    "    cluster_labels = DBSCAN(eps=5.0, min_samples=2, metric='euclidean').fit_predict(embeddings_dict[class_name])\n",
    "\n",
    "    # Dibujar\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for label in set(cluster_labels):\n",
    "        mask = cluster_labels == label\n",
    "        if label == -1:\n",
    "            # Outliers en rojo\n",
    "            plt.scatter(emb_2d[mask,0], emb_2d[mask,1], c='red', label='Outlier', alpha=0.6)\n",
    "        else:\n",
    "            plt.scatter(emb_2d[mask,0], emb_2d[mask,1], alpha=0.6, label=f'Cluster {label}')\n",
    "    plt.title(f'Clusters y outliers: {class_name}')\n",
    "    plt.xlabel('PCA 1')\n",
    "    plt.ylabel('PCA 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
